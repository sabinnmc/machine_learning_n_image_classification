{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabinnmc/machine_learning_n_image_classification/blob/main/memory_buffer_%2B_EWC_in_MLP_method_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dsyy2uESyJ2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "xdD0zTx0EcOl",
        "outputId": "1655427c-8895-432b-fd9f-ee2adaebd880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU name: NVIDIA GeForce RTX 2060 SUPER\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9y2XlKgaYvK"
      },
      "source": [
        "# Data preparation -> define tranformation for augmentation and normalization\n",
        "\n",
        "`transforms.RandomHorizontalFlip()` ->\n",
        "*   its tranforms flip image into its mirror image with 50% probability\n",
        "*   it effectively doubles our datsets without collecting lots of data\n",
        "*   flipping teaches model recognize real world sceanrio data more clearly\n",
        "*   improve generalization pattern of model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exy--3cAaMnY"
      },
      "outputs": [],
      "source": [
        "# checking for GPU availblivity\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\" )\n",
        "\n",
        "# for reproducibilty of same randomness\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(42)\n",
        "\n",
        "# data preparation\n",
        "# tranform to tensor and normalize them using mean and std\n",
        "transform_train = transforms.Compose([\n",
        "    # transforms.RandomCrop(32, padding = 4),       # get 32*32 pixel chunk from image and add 4 pixel around that 32*32 -> 40*40\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),     # mean tuple\n",
        "                         (0.2470, 0.2435, 0.2616))])   # standard deviation  tuple\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2470, 0.2435, 0.2616))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "winHZ0Jccx8E"
      },
      "source": [
        "# Downloading data and loding CIFAR-10 dataset\n",
        "\n",
        "# 1. what is tranform?\n",
        "\n",
        "\n",
        "*   optional callable\n",
        "*   Input -> PIL(python imaging Library) image or tensor\n",
        "*   output -> tranformed version of image\n",
        "*   similar to personal image editor that crop, flip or adjust image and prepare data for training and interence\n",
        "*   transforms.RandomCrop  -> randomly crop PIL image to specified size(32*32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehMc5sxcv-3",
        "outputId": "77fc62f2-fe98-4150-db39-86ca2cd63a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data sets number : 50000\n",
            "Testing data sets number:   10000\n",
            "Data type: <class 'torch.Tensor'> and Label types : <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    # root = '/content/drive/MyDrive/Colab Notebooks/CIFAR_10 dataset',\n",
        "    root = \"lab/tree/model_resnet\",\n",
        "    train = True,                                     # used for training purpose\n",
        "    download = True,                                  # download and put in \"root\" directory\n",
        "    transform = transform_train               # it takes PIL image or tensor-> return tranformed version\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    # root = \"/content/drive/MyDrive/Colab Notebooks/CIFAR_10 dataset\",\n",
        "    root = \"lab/tree/model_resnet\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform_test\n",
        ")\n",
        "\n",
        "#reading data info\n",
        "print(f\"Training data sets number : {len(train_dataset)}\")\n",
        "print(f\"Testing data sets number:   {len(test_dataset)}\")\n",
        "# chckinf data and label return values\n",
        "data, labels = train_dataset[0]\n",
        "print(f\"Data type: {type(data)} and Label types : {type(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDSLmP7iEcOx"
      },
      "source": [
        "## Splitting Task for CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTSJvmrMEcOy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "import random\n",
        "# here \" dataset = train_dataset \" which is a global variable and it is passed when it is called at Cl calling\n",
        "# whole dataset is splitted into task i.e 50k / num of task\n",
        "#\n",
        "def splitting_task(dataset, num_tasks):\n",
        "    dataset_size = len(dataset)          # Total number of sample in dataset\n",
        "    idx = list(range(dataset_size))      # Create list of indices 0,1,2,............\n",
        "    random.shuffle(idx)                  # shuffle for creating randomness of data\n",
        "    split_size = dataset_size // num_tasks  ## integer divion is done e.g 1000 / 5 = 250 -> one task have 250 data\n",
        "    task_idx = []                         # for storing indices as data are shuffled\n",
        "\n",
        "    for i in range(num_tasks):\n",
        "        start_idx = i * split_size    # say 0, 10k, 20k, 30k,40k\n",
        "        end_idx = (i + 1) * split_size if i < num_tasks -1 else dataset_size  # 10k, 20k, 30k, 40k, 50k\n",
        "        task_idx.append(idx[start_idx:end_idx])\n",
        "\n",
        "    tasks = [Subset(dataset, idx_counter) for idx_counter in task_idx]\n",
        "\n",
        "    return tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iig6r8dl9K2"
      },
      "source": [
        "# creating a data loader and sepcifying a class in CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPTyTsdvpfEB",
        "outputId": "d4d1f947-c7f6-4d2f-8c42-1ce63f0e4830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "maximum number of worker =  16\n"
          ]
        }
      ],
      "source": [
        "# number of core in default google collab  =  2\n",
        "import os\n",
        "print(\"maximum number of worker = \", os.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyrcC7jirYlg"
      },
      "source": [
        "# Why transpose is important before display?\n",
        "*   reordering dimension from (C, H, W) -> (H, W, C)\n",
        "*   image in tensors(PyTorch/TensorFlow) are [channels, Height, width]\n",
        "*   image in numpy, OpenCV, PIL, matplotlib are [height, width, channels]  \n",
        "\n",
        "# DataLoader  -> return a tuple (images, labels)\n",
        "images = tensor of shape [batch_size, channels, height, width]\n",
        "labels = tensor of shape [batch_size]\n",
        "iter() function -> convert dataloader into iterator and ready to dispatch one batch at time\n",
        "next() function -> retrives next item from iterator(i.e. 1st batch, 2nd...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLF0dBHPl4dm"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size = 128,\n",
        "                              shuffle = True,\n",
        "                              num_workers = 2)\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                             batch_size = 64,\n",
        "                             shuffle = False,\n",
        "                             num_workers = 2)\n",
        "\n",
        "# define class in CIFAR-10\n",
        "classes = ('airplane', 'automobile','bird','cat','deer',\n",
        "           'dog','frog','horse','ship','truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ijhEHO0wF1"
      },
      "source": [
        "# Building Resnet(Residual Network) Architecture\n",
        "\n",
        "Q . how output dimension can be preserved using padding?\n",
        "*   suppose i/p tensor = (1,1,5,5) -> (batch_size, i/p channels, height, weight)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*   **No padding:**\n",
        "output size = (1, o/p_channel, 3,3) as 3*3 kernel reduce dimension by 2*(5-(3-1)) = 2*(3)\n",
        "\n",
        "---\n",
        "* **with padding = 1:**\n",
        "input_size  = (1, o/p_channel, 7,7) -> add 1 pixel all around input features\n",
        "output_size = (1, o/p_channel, 5,5) -> as 3*3 kernel reduce dimesnion by 2*(7-(3-1)) = 2* (5)\n",
        "therefore, original spatial size is preserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptr382kJ0mfI"
      },
      "outputs": [],
      "source": [
        "class BasicResNet_block(nn.Module):\n",
        "  expansion = 1\n",
        "  # for bottle neck (used ib ResNets(50,101,152))\n",
        "  #expansion = 4\n",
        "  def __init__(self, in_channels, out_channels, stride = 1):\n",
        "    super(BasicResNet_block, self).__init__()\n",
        "    # first convolution\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels,\n",
        "                           kernel_size = 3,\n",
        "                           stride = stride,      # take jump of each pixel at a time\n",
        "                           padding = 1,     # adding 1 pixel around input features map(i/p tensor)\n",
        "                           bias = False)    # False -> not learnable and won`t be updated\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
        "                           kernel_size = 3,\n",
        "                           stride = 1,\n",
        "                           padding = 1,\n",
        "                           bias = False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    # skip connection is performed by \"shortcut\"\n",
        "    self.shortcut = nn.Sequential()\n",
        "    # if dimension change , we need to adjust shortcut connection\n",
        "    if stride !=1 or in_channels != self.expansion * out_channels:    # this occur only in bottlneck not in simple ResNet\n",
        "      self.shortcut = nn.Sequential(nn.Conv2d(in_channels,\n",
        "                                              self.expansion * out_channels,      # here output channel is changed in bottleneck ResNet\n",
        "                                              kernel_size = 1, # 1\n",
        "                                              stride = stride,\n",
        "                                              bias = False),\n",
        "                                    nn.BatchNorm2d(self.expansion * out_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out += self.shortcut(x)\n",
        "    out = self.relu(out)\n",
        "    return out\n",
        "\n",
        "# define ResNet model\n",
        "class ResNet_model(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes = 10):\n",
        "    super(ResNet_model, self).__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv1 = nn.Conv2d(3, 64,\n",
        "                           kernel_size = 3,\n",
        "                           stride = 1,\n",
        "                           padding = 1,\n",
        "                           bias = False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU()\n",
        "    # memo : block = BasicResNet_block class instance\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride = 1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride = 2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride = 2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride = 2)\n",
        "    self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks - 1)\n",
        "    # output is [1,1],[2,1],[2,1],[2,1]\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      # here block is BasicResNet_block class instance\n",
        "      layers.append(block(self.in_channels, out_channels, stride))\n",
        "      self.in_channels = out_channels * block.expansion\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)   # 32*32*3 -> 32*32*64\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.layer1(out)      # stride=1, size = N*32*32*64\n",
        "    out = self.layer2(out)      # stride=2, size = N*16*16*128\n",
        "    out = self.layer3(out)      # stride=2, size = N*8*8*256\n",
        "    out = self.layer4(out)      # stride=2, size = N*4*4*512\n",
        "    out = F.avg_pool2d(out, 4)  # agerage down 4*4 kernel to size = 1*1*512 -> preparing for linear layer\n",
        "    out = out.view(out.size(0), -1)   # flatten to (batch_size, 512)\n",
        "    out = self.linear(out)            #  N*512*1 = N*512 input features\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L_G9mClEcO8",
        "outputId": "ccca2bd8-8d54-468a-e848-28c427208abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameter: 11,173,962\n"
          ]
        }
      ],
      "source": [
        "model = ResNet_model(BasicResNet_block,[2, 2, 2, 2]).to(device)\n",
        "# [2,2,2,2] is a \"num_blocks\" argument passed for ResNet_model\n",
        "# print(model)\n",
        "# define a loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay= 5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 30)\n",
        "\n",
        "# count the number of paramter\n",
        "# .numel() is a method in PyTorch .\"number of elements\"\n",
        "total_parameter = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameter: { total_parameter:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InZ6ECy_V6v1"
      },
      "source": [
        "# Training and Evalution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9kUn7NBHDQY"
      },
      "outputs": [],
      "source": [
        "# train function\n",
        "def train_epoch(model, train_dataloader,optimizer, criterion, save_dir, train_epochs = 30):\n",
        "  model.train()\n",
        "  train_loss_list = []\n",
        "  train_accuracy_list = []\n",
        "  for epoch in range(train_epochs):\n",
        "    train_ok_count = 0\n",
        "    train_total = 0\n",
        "    train_epoch_loss = 0\n",
        "    for i, (data,labels) in enumerate(train_dataloader, 0):\n",
        "\n",
        "      # tranfer data and label to same device\n",
        "      data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "      # zero the parameter gardient\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(data)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_epoch_loss += loss.item()\n",
        "      scheduler.step()\n",
        "      # for training accuracy\n",
        "      with torch.no_grad():\n",
        "        maximum_predict, max_predicted_index = torch.max(outputs.data,1)\n",
        "        # total number of target size\n",
        "        train_total += labels.size(0)\n",
        "        train_ok_count += (max_predicted_index == labels).sum().item()\n",
        "    if save_dir is not None:\n",
        "        torch.save(model.state_dict(), f\"{save_dir}/epoch_{epoch}.pth\")\n",
        "\n",
        "    avg_loss = train_epoch_loss / len(train_dataloader)\n",
        "    train_loss_list.append(avg_loss)\n",
        "    # efficacy calculate\n",
        "    train_accuracy = train_ok_count / train_total * 100\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "    #print(f\"Epoch: {epoch + 1}, Training loss: {avg_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "  return train_accuracy_list, train_loss_list\n",
        "\n",
        "def test_epoch(model, test_dataloader, criterion, save_dir, test_epochs = 30):\n",
        "\n",
        "    # model.load_state_dict(torch.load(f\"/content/drive/MyDrive/Colab Notebooks/CIFAR_10 model location/epoch_{epoch}.pth\"))\n",
        "    test_loss_list = []\n",
        "    test_accuracy_list = []\n",
        "    #model.load_state_dict(torch.load(f\"{save_dir}/epoch_29.pth\"))\n",
        "    for epoch in range(test_epochs):\n",
        "\n",
        "        model.load_state_dict(torch.load(f\"{save_dir}/epoch_29.pth\"))\n",
        "        model.eval()\n",
        "        test_epoch_loss = 0\n",
        "        test_ok_count = 0\n",
        "        test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, labels) in enumerate(test_dataloader, 0):\n",
        "\n",
        "            #print(f\"Batch {i}: Data type: {type(data)}, Labels type: {type(labels)}\")\n",
        "            # tranfer data and label to same device\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            test_output = model(data)\n",
        "            test_loss = criterion(test_output, labels)\n",
        "            test_epoch_loss += test_loss.item()\n",
        "\n",
        "            # calculating accuracy and loss during evalution mode\n",
        "            maxmimum_predict, max_predict_idx = torch.max(test_output.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_ok_count += (max_predict_idx == labels).sum().item()\n",
        "\n",
        "    average_loss = test_epoch_loss / len(test_dataloader)\n",
        "    test_loss_list.append(average_loss)\n",
        "    test_accuracy = test_ok_count / test_total * 100\n",
        "    test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}, Testing loss: {average_loss:.4f}, Testing accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return test_accuracy_list, test_loss_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdMn1pJlEcPA"
      },
      "source": [
        "# Splitting a task for catastrophic forgetting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWhLKniYEcPB",
        "outputId": "f7351529-739f-4703-fded-b0056c536ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "[<torch.utils.data.dataset.Subset object at 0x7489f6457740>, <torch.utils.data.dataset.Subset object at 0x7489f647d9d0>, <torch.utils.data.dataset.Subset object at 0x7489f647e3c0>, <torch.utils.data.dataset.Subset object at 0x7489f647dd30>, <torch.utils.data.dataset.Subset object at 0x7489f647f230>]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# calling a splitting_task defintion to split the total  training dataset into fraction\n",
        "num_tasks = 5\n",
        "epoch_per_task = 20\n",
        "tasks = splitting_task(train_dataset, num_tasks)\n",
        "print(len(tasks))\n",
        "print(tasks)\n",
        "\n",
        "\n",
        "save_dir_catastropic = \"/home/sabinnmc/work/image_classification/catastrophic forgetting model\"\n",
        "os.makedirs(save_dir_catastropic, exist_ok=True)  # Creates the folder if it’s not there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7cDZ5UHEcPC"
      },
      "source": [
        "# Tracking all the accuracy and buliding a matrix of accuracy for comparing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTpnvwut3tdw"
      },
      "source": [
        "# Training loop and testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmtLKFrKEcPD"
      },
      "outputs": [],
      "source": [
        "# tracking acccuracy for output anlaysis\n",
        "train_accuracy_splitList = []\n",
        "test_accuracy_by_split_on_whole  = []\n",
        "test_accuracy_splitList = []\n",
        "clock = 1\n",
        "for task_id, task_dataset in enumerate(tasks):\n",
        "\n",
        "    train_accuracy_list_1 = []\n",
        "    test_accuracy_list_1  = []\n",
        "    split_dataloader = DataLoader(task_dataset,\n",
        "                                 batch_size = 128,\n",
        "                                 shuffle = True,\n",
        "                                 num_workers = 2)\n",
        "    train_accuracy_list_1, _ = train_epoch(model, split_dataloader, optimizer, criterion, save_dir_catastropic)\n",
        "    train_accuracy_splitList.append(train_accuracy_list_1)\n",
        "    print(\"\\n Test of last epoch on all test dataset. \")\n",
        "    test_accuracy_list_1, _ = test_epoch(model, test_dataloader, criterion, save_dir_catastropic)\n",
        "    test_accuracy_by_split_on_whole.append(test_accuracy_list_1)\n",
        "    accuracies_chora = []\n",
        "    print(\"\\n Evaluation of past already Train dataset\")\n",
        "    for counter in range(clock):\n",
        "        test_accuracy_list_child = []\n",
        "\n",
        "        child_dataloader = DataLoader(tasks[counter],\n",
        "                                     batch_size = 128,\n",
        "                                     shuffle = True,\n",
        "                                     num_workers = 2)\n",
        "\n",
        "        print(f\"\\n Evaluation of task number {counter} / {clock}\")\n",
        "        test_accuracy_list_child, _ = test_epoch(model, child_dataloader, criterion, save_dir_catastropic)\n",
        "        accuracies_chora.append(test_accuracy_list_child)\n",
        "    # chora ko list inside bau ko main list vitra vai\n",
        "    test_accuracy_splitList.append(accuracies_chora)\n",
        "    clock += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV4hxJzuEcPF"
      },
      "outputs": [],
      "source": [
        "# convert to  a NumPy array to match table structure\n",
        "n_tasks = len(tasks)\n",
        "# intializing all element as NaN\n",
        "test_accuracy_matrix = np.full((n_tasks, n_tasks), np.nan)\n",
        "for i in range(n_tasks):\n",
        "    for ticker in range(0, i + 1):\n",
        "        accuracy = test_accuracy_splitList[i][ticker]\n",
        "        test_accuracy_matrix[i, ticker] = accuracy[-1] if isinstance(accuracy, list) else accuracy\n",
        "print(test_accuracy_matrix)\n",
        "print(test_accuracy_matrix.dtype)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5JzXL84EcPF"
      },
      "source": [
        "# plotting a graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3NhcgpkEcPG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "colors = [\"b\", \"g\", \"r\", \"c\", \"m\"]\n",
        "labels = [f\" Test Task {i}\" for i in range(5)]\n",
        "ticker = 0\n",
        "for counter in range(5):\n",
        "    column_data = test_accuracy_matrix[:, counter]\n",
        "    valid_data  = column_data[~np.isnan(column_data)]\n",
        "    # valid_data = test_accuracy_matrix[counter,:counter + 1]\n",
        "    valid_indices = np.where(~np.isnan(column_data))[0]\n",
        "    ticker -= 1\n",
        "    # plt.plot(range(counter  +1), valid_data, marker = 'o', color = colors[counter], label = labels[counter] )\n",
        "    plt.plot(valid_indices, valid_data, marker='o', linestyle='-', linewidth=2, markersize=8, color=colors[counter],\n",
        "             label=labels[counter])\n",
        "plt.title(\"Test accuracies per training Task\")\n",
        "plt.xlabel(\"Evaluation Task\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zua6OePoEcPH"
      },
      "source": [
        "# <center> Comparing MLP with ResNet-18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtv8ODezEcPH"
      },
      "source": [
        "# Equivalenting ResNet18 into MLP for catastrophic forgetting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYf0riYkEcPI"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\" input size = 32 * 32 * 3 = weight * height * channel = 3072\n",
        "    -> output layer = task is splitted into two tasks (5 per each task)\n",
        "    -> mm.Faltten() = flat image to linear = 32 * 32 * 3 = 3072\n",
        "    \"\"\"\n",
        "    def __init__(self, input_feature = 3072, hidden_layer = 1024, num_classes = 10):\n",
        "        super().__init__()\n",
        "        \"\"\" 1. reason for falttening a data\n",
        "        If the input to an nn.Linear layer comes from a layer that outputs a multi-dimensional tensor (e.g., a convolutional layer\n",
        "        with shape (batch_size, channels, height, width) or a pooling layer),\n",
        "        you need to flatten it into a 1D tensor (e.g., (batch_size, channels * height * width)).\n",
        "        \"\"\"\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # define layer\n",
        "        self.func1 = nn.Linear(input_feature, hidden_layer)\n",
        "        self.bn1   = nn.BatchNorm1d(1024)\n",
        "        self.func2 = nn.Linear(1024, 512)\n",
        "        self.bn2   = nn.BatchNorm1d(512)\n",
        "        self.func3 = nn.Linear(512, 256)\n",
        "        self.bn3   = nn.BatchNorm1d(256)\n",
        "        self.func4 = nn.Linear(256, num_classes)\n",
        "        self.bn4   = nn.BatchNorm1d(10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        # first hidden layer\n",
        "        x = self.dropout(self.relu(self.bn1(self.func1(x))))\n",
        "        # second hidden layer\n",
        "        x = self.dropout(self.relu(self.bn2(self.func2(x))))\n",
        "        # third hidden layer\n",
        "        x = self.dropout(self.relu(self.bn3(self.func3(x))))\n",
        "        # output layer\n",
        "        x = self.func4(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4JXR11IEcPJ"
      },
      "outputs": [],
      "source": [
        "# calling MLP\n",
        "model_MLP = MLP().to(device)\n",
        "# print(model)\n",
        "# define a loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "optimizer = optim.SGD(model_MLP.parameters(), lr=0.01, momentum=0.9, weight_decay= 5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ohld-UQEcPJ"
      },
      "outputs": [],
      "source": [
        "save_dir_mlp = \"/home/sabinnmc/work/image_classification/model_MLP\"\n",
        "os.makedirs(save_dir_mlp, exist_ok=True)  # Creates the folder if it’s not there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxkYy-A2EcPK"
      },
      "source": [
        "# Runnig same ResNet-18 model style but using <b><span style = \"color: red\">MLP(Multi layer Perceptron)</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VojHe-Q2EcPL"
      },
      "outputs": [],
      "source": [
        "# tracking acccuracy for output anlaysis\n",
        "train_accuracy_splitList = []\n",
        "test_accuracy_by_split_on_whole  = []\n",
        "test_accuracy_splitList = []\n",
        "clock = 1\n",
        "for task_id, task_dataset in enumerate(tasks):\n",
        "\n",
        "    train_accuracy_list_1 = []\n",
        "    test_accuracy_list_1  = []\n",
        "    split_dataloader = DataLoader(task_dataset,\n",
        "                                 batch_size = 128,\n",
        "                                 shuffle = True,\n",
        "                                 num_workers = 2)\n",
        "    train_accuracy_list_1, _ = train_epoch(model_MLP, split_dataloader, optimizer, criterion, save_dir_mlp)\n",
        "    train_accuracy_splitList.append(train_accuracy_list_1)\n",
        "    print(\"\\n Test of last epoch on all test dataset. \")\n",
        "    test_accuracy_list_1, _ = test_epoch(model_MLP, test_dataloader, criterion, save_dir_mlp)\n",
        "    test_accuracy_by_split_on_whole.append(test_accuracy_list_1)\n",
        "    accuracies_chora = []\n",
        "    print(\"\\n Evaluation of past already Train dataset\")\n",
        "    for counter in range(clock):\n",
        "        test_accuracy_list_child = []\n",
        "\n",
        "        child_dataloader = DataLoader(tasks[counter],\n",
        "                                     batch_size = 128,\n",
        "                                     shuffle = True,\n",
        "                                     num_workers = 2)\n",
        "\n",
        "        print(f\"\\n Evaluation of task number {counter} / {clock}\")\n",
        "        test_accuracy_list_child, _ = test_epoch(model_MLP, child_dataloader, criterion, save_dir_mlp)\n",
        "        accuracies_chora.append(test_accuracy_list_child)\n",
        "    # chora ko list inside bau ko main list vitra vai\n",
        "    test_accuracy_splitList.append(accuracies_chora)\n",
        "    clock += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg2o4scNEcPM"
      },
      "outputs": [],
      "source": [
        "# convert to  a NumPy array to match table structure\n",
        "n_tasks = len(tasks)\n",
        "# intializing all element as NaN\n",
        "test_accuracy_matrix = np.full((n_tasks, n_tasks), np.nan)\n",
        "for i in range(n_tasks):\n",
        "    for ticker in range(0, i + 1):\n",
        "        accuracy = test_accuracy_splitList[i][ticker]\n",
        "        test_accuracy_matrix[i, ticker] = accuracy[-1] if isinstance(accuracy, list) else accuracy\n",
        "print(test_accuracy_matrix)\n",
        "print(test_accuracy_matrix.dtype)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiH9VZtwEcPN"
      },
      "source": [
        "# Plotting graph using MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxSYVMfDEcPO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "colors = [\"b\", \"g\", \"r\", \"c\", \"m\"]\n",
        "labels = [f\" Test Task {i}\" for i in range(5)]\n",
        "ticker = 0\n",
        "for counter in range(5):\n",
        "    column_data = test_accuracy_matrix[:, counter]\n",
        "    valid_data  = column_data[~np.isnan(column_data)]\n",
        "    # valid_data = test_accuracy_matrix[counter,:counter + 1]\n",
        "    valid_indices = np.where(~np.isnan(column_data))[0]\n",
        "    ticker -= 1\n",
        "    # plt.plot(range(counter  +1), valid_data, marker = 'o', color = colors[counter], label = labels[counter] )\n",
        "    plt.plot(valid_indices, valid_data, marker='o', linestyle='-', linewidth=2, markersize=8, color=colors[counter],\n",
        "             label=labels[counter])\n",
        "plt.title(\"Test accuracies per training Task\")\n",
        "plt.xlabel(\"Evaluation Task\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgRxGZnnEcPP"
      },
      "source": [
        "# <center><u><b>Continual Learning Implementation</b></u></center>\n",
        "<ol><h2>\n",
        "    <li>Using Memory Buffer </li>\n",
        "    <li> Using Elastic Weight Consolidation (EWC) </li>\n",
        "</h2>\n",
        "</ol>Regularization based Approch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWRnYLiwEcPQ"
      },
      "source": [
        "# <center> <B> 1.  Using Memory Buffer </B> </center>\n",
        "## 1.1 Memory Dataset class definition for fetching sample and returning (x,y) tuple and number of sample\n",
        "<ul><li> This class inherit from class to create a custom datset from Pytorch <code style=\"color: red;\"> torch.utils.data </code></li>\n",
        "<li><code style=\"color: red;\"> Dataset </code> class is part of PyTorch data loading pipeline whivh provide standard interface for accessing data samples </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwXSclIhEcPQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "# When we have custom data that doesn’t fit into pre-built datasets the  this is import\n",
        "class MemoryDataset(Dataset):\n",
        "    def __init__(self, x_data, y_data, transform):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        self.transform = transform\n",
        "\n",
        "    \"\"\" Fetches a single data sample from your dataset based on the provided index.\n",
        "        -> It returns a tuple (x, y) where:\n",
        "        -> x is the input data ( an image) at position index in self.x_data.\n",
        "        -> y is the corresponding label or target (e.g., a class label) at position index in self.y_data.\n",
        "    \"\"\"\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.x_data[index], self.y_data[index]\n",
        "        # convert tensor to PIL imgage transformer\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            if x.dim() == 3 and x.shape[0] == 3:                  #[C, H, W] format confirmation\n",
        "                # converting numpy and then PIL\n",
        "                x_np = x.numpy()\n",
        "                if x_np.max() <=1.0:\n",
        "                    x_np = (x_np * 255).astype(np.uint8)\n",
        "                else:\n",
        "                    x_np = x_np.astype(np.uint8)\n",
        "                # convert to [H, W, C] for PIL\n",
        "                x_np = np.transpose(x_np, (1,2,0))\n",
        "                x = Image.fromarray(x_np)\n",
        "        if self.transform:\n",
        "            # # Convert tensor to PIL Image (assuming x is an image tensor)\n",
        "            # x = x.cpu().numpy()  # Convert tensor to NumPy array\n",
        "            # x = Image.fromarray(x.astype('uint8'), 'RGB')  # Convert to PIL Image (adjust mode as needed)\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "    \"\"\"\n",
        "    Return number of samples from samples from dataset\n",
        "    \"\"\"\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQtN6VqREcPR"
      },
      "source": [
        "##  1.2 Memory Buffer class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKwa0PCdEcPk"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "class MemoryBuffer:\n",
        "    def __init__(self, capacity = 1000):\n",
        "        self.capacity = capacity\n",
        "        self.memory_x = []\n",
        "        self.memory_y = []\n",
        "        # defaultdict can count the frequency of data or labels\n",
        "        self.class_counts = defaultdict(int)\n",
        "\n",
        "    def add_sample(self, x, y):\n",
        "\n",
        "        \"\"\" .detach() remove tensor \"x\" (image) from computational graph i.e. no longer track gradients\n",
        "                -> beacuse in CL, memory buffer store sample for later use not for immediate gradient compute\n",
        "                -> if not detached , consume memory and compute resource unncessarily\n",
        "        .cpu() remove tensor from GPU to CPU because memory buffer are oftern stored in CPU rather then GPU\n",
        "                -> GPU are expensive and its resource are used carefully for computation not for storing\n",
        "                ->  CL invloves long term storage of samples across tasks and keeping is GPU is not good idea\n",
        "                ->  Transfering data from CPU to GPU doesnot create memory bottleneck but vice versa will do\n",
        "        \"\"\"\n",
        "        x = x.detach().cpu()\n",
        "        y = y.item()        if isinstance(y, torch.Tensor) else y\n",
        "        #_______________________________________________________________________________________\n",
        "        #  determing a balanced buffer eith sample number of sample for each class\n",
        "        # ____________________________________________________________________ for future__________________\n",
        "        if len(self.memory_x) < self.capacity:\n",
        "            self.memory_x.append(x)\n",
        "            self.memory_y.append(y)\n",
        "            self.class_counts[y] += 1\n",
        "        else:\n",
        "            max_class = max(self.class_counts, key = self.class_counts.get)\n",
        "            idx = [i for i, label in enumerate(self.memory_y) if label == max_class]\n",
        "            # class balacing by random sampling\n",
        "            # random_idx = buffer_size / total_samples_seen\n",
        "            if idx:\n",
        "                replace_idx = random.choice(idx)\n",
        "                self.class_counts[self.memory_y[replace_idx]] -= 1\n",
        "                self.memory_x[replace_idx] = x\n",
        "                self.memory_y[replace_idx] = y\n",
        "                self.class_counts[y] += 1               # since we just data so count of y label will increase by 1\n",
        "\n",
        "    def get_memory_dataset(self, transform = None):\n",
        "      # creating a dataset from memory samples\n",
        "      memory_dataset = MemoryDataset(self.memory_x, self.memory_y, transform)\n",
        "      return memory_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.memory_x)\n",
        "\n",
        "    def get_class_distribution(self, class_counts):\n",
        "      # return class distribution in the memory buffer\n",
        "      return dict(self.class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN68-WaEcPl"
      },
      "source": [
        "# 1.3 (i) Training model with Memory Buffer\n",
        "<code>def train_epoch(model, train_dataloader,optimizer, criterion, save_dir, train_epochs = 30):\n",
        "def test_epoch(model, test_dataloader, criterion, save_dir, test_epochs = 30):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MDhW6SREcPm"
      },
      "outputs": [],
      "source": [
        "# train function\n",
        "def train_with_memory(model_MLP, memory_buffer,optimizer, criterion, train_epochs = 30):\n",
        "  # creating a new dataset for using memory buffer\n",
        "  memory_dataset = memory_buffer.get_memory_dataset(transform_train)   # transform_train is defined as global variable at top\n",
        "  memory_dataloader = DataLoader(memory_dataset, batch_size = 128, shuffle = True)\n",
        "  print(f\"\\nMemory dataloader during training with memory is : size( {len(memory_buffer)} )\")\n",
        "\n",
        "  return train_epoch(model_MLP, memory_dataloader,optimizer, criterion, save_dir = None, train_epochs = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j26Ca1lKEcPn"
      },
      "source": [
        "#  1.5 Train on task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZkrb1YFEcPn"
      },
      "outputs": [],
      "source": [
        "def train_with_task(model_MLP, task_dataset, memory_buffer, optimizer, criterion, train_epochs = 10):\n",
        "    # Creating a new dataset for using memory buffer\n",
        "    task_train_dataloader = DataLoader(task_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "    model_MLP.train()\n",
        "    train_loss_list = []\n",
        "    train_accuracy_list = []\n",
        "\n",
        "    accuracy_list, loss_list = train_epoch(model_MLP, task_train_dataloader,optimizer, criterion, save_dir = None, train_epochs = 30)\n",
        "    # Initializing before using\n",
        "    memory_dataloader = None\n",
        "    memory_iteration = None\n",
        "\n",
        "    # # Create a combined dataset if memory buffer has samples\n",
        "    # if memory_buffer is not None and len(memory_buffer) > 0:\n",
        "    #     # transform_train is global object used for augmentation\n",
        "    #     memory_dataset = memory_buffer.get_memory_dataset(transform_train)\n",
        "    #     # Oversample memory data (increasing weight of old data)\n",
        "    #     memory_dataloader = DataLoader(memory_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "    #     memory_iteration = iter(memory_dataloader)\n",
        "\n",
        "    # UPDATE memory buffer with samples from current task if needed\n",
        "    if memory_buffer is not None:\n",
        "        # add samples to memory buffer here and this part is missing\n",
        "        for i, (data, labels) in enumerate(task_train_dataloader):\n",
        "            for j in range(len(data)):\n",
        "                if random.random() < 0.01:  # Sample with 1% probability to avoid bias\n",
        "                    memory_buffer.add_sample(data[j].cpu(), labels[j].item())\n",
        "\n",
        "    return accuracy_list, loss_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc_wQPwvEcPo"
      },
      "source": [
        "# 1.6 Running continual learning model\n",
        "## Definition of train and test\n",
        "<code>train_accuracy_list, train_loss_list = def train_epoch(model, train_dataloader,optimizer, criterion, save_dir, train_epochs = 30):\n",
        "<code>\n",
        "test_accuracy_list, test_loss_list = def test_epoch(model, test_dataloader, criterion, save_dir, test_epochs = 30):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1KzIaREcPp"
      },
      "source": [
        "<code>def train_with_task(model, task_dataset, memory_buffer, optimizer, criterion, train_epochs = 10):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyxX8-UMEcPq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "#def Continual_learning_experiment():\n",
        "num_tasks = 5\n",
        "memory_capacity = 1000\n",
        "epoch_per_task = 5\n",
        "\n",
        "memory_buffer = MemoryBuffer(capacity = memory_capacity)\n",
        "if memory_buffer is not None:\n",
        "    print(\" Object of class is not empty and it can train a model\")\n",
        "    print(\" length if memory buffer is : \", len(memory_buffer))\n",
        "# already called in above\n",
        "# tasks = splitting_task(train_dataset, num_tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWH7pf_CEcPr"
      },
      "outputs": [],
      "source": [
        "# Tracking accuracy and loss across all tasks\n",
        "train_accuracy_list_MB = []\n",
        "train_loss_list_MB = []\n",
        "train_accuracy_list_TASK = []\n",
        "train_loss_list_TASK = []\n",
        "test_accuracy_list_CL = []\n",
        "test_loss_list_CL = []\n",
        "\n",
        "# Tracking results when we train model using train_on_task method\n",
        "for task_id, task_dataset in enumerate(tasks):\n",
        "    print(f\"\\nTraining on Task {task_id + 1} / {num_tasks}\")\n",
        "    print(f\"\\nThe size of each task (size: {len(task_dataset)})\")\n",
        "\n",
        "    train_accuracy_list_task, train_loss_list_task = train_with_task(model_MLP,\n",
        "                                                  task_dataset,\n",
        "                                                  memory_buffer=memory_buffer,\n",
        "                                                  optimizer=optimizer,\n",
        "                                                  criterion=criterion,\n",
        "                                                  train_epochs=30)\n",
        "\n",
        "    # Store task training results\n",
        "    train_accuracy_list_TASK.append(train_accuracy_list_task)\n",
        "    train_loss_list_TASK.append(train_loss_list_task)\n",
        "\n",
        "    # Train on memory buffer after task (replay)\n",
        "    if memory_buffer is not None and len(memory_buffer) > 0:\n",
        "        print(f\"Training on memory buffer (size: {len(memory_buffer)})\")\n",
        "        train_accuracy_list_mb, train_loss_list_mb = train_with_memory(model_MLP,\n",
        "                                                       memory_buffer=memory_buffer,\n",
        "                                                       optimizer=optimizer,\n",
        "                                                       criterion=criterion,\n",
        "                                                       train_epochs=20)\n",
        "\n",
        "        # Store memory buffer training results\n",
        "        train_accuracy_list_MB.append(train_accuracy_list_mb)\n",
        "        # You might want to store loss too\n",
        "        # train_loss_list_MB.append(train_loss_list_mb)\n",
        "\n",
        "    # Evaluating after each task\n",
        "    print(f\"Evaluating on test dataset (size: {len(test_dataloader.dataset)})\")\n",
        "    test_accuracy_list_cl, test_loss_list_cl = test_epoch(model_MLP,\n",
        "                                                 test_dataloader,\n",
        "                                                 criterion,\n",
        "                                                 save_dir = save_dir_mlp ,\n",
        "                                                 test_epochs=30)\n",
        "    test_accuracy_list_CL.append(test_accuracy_list_cl)\n",
        "    test_loss_list_CL.append(test_loss_list_cl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5ZONPMNEcPs"
      },
      "source": [
        "# defining class for CutMix method\n",
        "\n",
        "# trying a cutMix approach\n",
        "\n",
        "\n",
        "\n",
        "1.  we are randomly selecting a number and if selection of number is less than 0.5   then we are performing CutMix idea\n",
        "2.   We are not using all images only randomly selected data are only mixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypfMASxMEcPt"
      },
      "outputs": [],
      "source": [
        "class CutMix(object):\n",
        "  def __init__(self, alpha= 0.1, prob = 0.5):\n",
        "    self.alpha = alpha\n",
        "    self.prob = prob\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    data, labels = batch\n",
        "    print(\"random.random return is \", random.random())\n",
        "\n",
        "    if random.random() >= self.prob:\n",
        "      return data, labels, None, None\n",
        "\n",
        "    index = torch.randperm(data.size(0))\n",
        "    shuffle_images = data[index]\n",
        "    # it is special beta distribution. related to beta distribution\n",
        "    lamda = np.random.beta(self.alpha,    # alpha > 0\n",
        "                            self.alpha)    # beta > 0\n",
        "    # data = images and tuples data look like (batch_no, channel, height, width)\n",
        "    img_ht, img_wd = data.shape[2:]\n",
        "    x_center = np.random.uniform(0, img_ht)   # creata random value among 0 <= value < img_ht\n",
        "    y_center = np.random.uniform(0, img_wd)\n",
        "    w = img_wd * np.sqrt(1 - lamda)\n",
        "    h = img_ht * np.sqrt(1 - lamda)\n",
        "    x0 = int(np.round(max(x_center - w / 2, 0)))\n",
        "    y0 = int(np.round(max(y_center - h / 2, 0)))\n",
        "    x1 = int(np.round(min(x_center + w / 2, img_wd)))\n",
        "    y1 = int(np.round(min(y_center + w / 2, img_ht)))\n",
        "\n",
        "    data[:, :, y0:y1, x0:x1] = shuffle_images[:, :, y0:y1, x0:x1]\n",
        "    # 1-total patch area/total_area -> 1- portion % of patch area -> real image section remaining after patch\n",
        "    lamda = 1 - ((x1 - x0) * (y1 - y0) /   (img_ht * img_wd))\n",
        "    return data, labels, lamda, index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcP04EkcEcPu"
      },
      "source": [
        "# Memory Buffer for replay based method (GDumb - paper method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_98wt-SEcPu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}